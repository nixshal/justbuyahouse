{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Get all links for a given Train Station ID"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train Station ID's"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "lrt_kelana_jaya_line_1 = ['gombak-543', 'ampang-park-89', 'pasar-seni-414', 'bangsar-625', 'asia-jaya-187', 'ara-damansara-415', 'usj-7-608', 'putra-heights-678', 'taman-melati-624', 'jelatek-51', 'masjid-jamek-600', 'abdullah-hukum-325', 'taman-paramount-466', 'glenmarie-250', 'taipan-719', 'subang-alam-584', 'wangsa-maju-276', 'dato-keramat-607', 'kampung-baru-121', 'kerinchi-431', 'taman-bahagia-529', 'subang-jaya-1', 'wawasan-432', 'sri-rampai-513', 'damai-683', 'dang-wangi-291', 'universiti-168', 'kelana-jaya-260', 'ss-15-316', 'usj-21-531', 'setiawangsa-20', 'klcc-666', 'kl-sentral-438', 'taman-jaya-560', 'lembah-subang-170', 'ss-18-189', 'alam-megah-23']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Get all links from a Train Station ID"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import requests\r\n",
    "from bs4 import BeautifulSoup\r\n",
    "from time import sleep\r\n",
    "from itertools import chain\r\n",
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "import re"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# url = 'https://www.iproperty.com.my/rent/all-residential/transport/kl-sentral-438'\r\n",
    "# headers = {'User-Agent' : 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.107 Safari/537.36'}\r\n",
    "# response= requests.get(url, headers=headers)\r\n",
    "# print(response)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# BeautifulSoup stuff\r\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.107 Safari/537.36'}\r\n",
    "\r\n",
    "page_num = 0\r\n",
    "\r\n",
    "links = []\r\n",
    "for page in range(0,1):\r\n",
    "    page_num += 1\r\n",
    "    iproperty_url = 'https://www.iproperty.com.my/rent/all-residential/transport/kl-sentral-438/?page=' + \\\r\n",
    "        str(page_num)\r\n",
    "    r = requests.get(iproperty_url, headers=headers)\r\n",
    "    print(r)\r\n",
    "    sleep(5)\r\n",
    "    print('Now scraping page ' +str(page_num))\r\n",
    "    soup = BeautifulSoup(r.content, 'html.parser')\r\n",
    "    for link in soup.findAll('a'):\r\n",
    "        # print(link.get('href'))\r\n",
    "        links.append(link.get('href'))\r\n",
    "\r\n",
    "links = [i for i in links if i] #removes None\r\n",
    "print(len(links))\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "print('**********ALL LINKS FOR TRAIN STATION ID: ' + 'COMPLETE**********')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "to_remove = ['http','tel','photo','video','floorplan']\r\n",
    "\r\n",
    "filtered_list = [ i for i in links if \"http\" not in i and \"tel\" not in i and \"photo\" not in i and \"video\" not in i and \"floorplan\" not in i and len(i) > 10]\r\n",
    "\r\n",
    "# for loop implementation\r\n",
    "# for i in links:\r\n",
    "#     if \"http\" not in i and \"tel\" not in i and \"photo\" not in i and \"video\" not in i and \"floorplan\" not in i and len(i) > 10:\r\n",
    "#         nlist.append(i)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df = pd.DataFrame(filtered_list, columns=[\"links\"])\r\n",
    "\r\n",
    "df.drop_duplicates(inplace=True)\r\n",
    "\r\n",
    "filename = iproperty_url.split('/')\r\n",
    "filename = filename[3] + '-' + filename[6] + '-' + 'property-links' + '.csv'\r\n",
    "\r\n",
    "df.to_csv(filename, index=False) #to print to a csv"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Scrape data from just 1 property link"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "source": [
    "import requests\r\n",
    "from bs4 import BeautifulSoup\r\n",
    "from time import sleep\r\n",
    "import itertools\r\n",
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "import re"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# sample = ['/property/kl-city/ceylonz-suites/rent-102322211/']\r\n",
    "# sample2 = '/property/bangsar/serai/rent-101410606/'\r\n",
    "\r\n",
    "# url = 'https://www.iproperty.com.my' + sample2\r\n",
    "# url\r\n",
    "\r\n",
    "# d = pd.read_csv('hardcopy-rent-kl-sentral-438-property-links.csv').values.tolist()\r\n",
    "# links = list(itertools.chain(*d))\r\n",
    "\r\n",
    "# test_list = links[0:2]\r\n",
    "\r\n",
    "# print(test_list)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# headers = {'User-Agent' : 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.107 Safari/537.36'}\r\n",
    "# response= requests.get(url, headers=headers)\r\n",
    "# print(response)\r\n",
    "\r\n",
    "# soup = BeautifulSoup(response.content, 'html.parser')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "d = pd.read_csv(\r\n",
    "    'hardcopy-rent-kl-sentral-438-property-links.csv').values.tolist()\r\n",
    "links = list(itertools.chain(*d))\r\n",
    "test_list = links[3:5]\r\n",
    "\r\n",
    "print('\\n')\r\n",
    "print(test_list)\r\n",
    "print('\\n')\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "\n",
      "['/property/kl-city/ceylonz-suites/rent-102322211/', '/property/bangsar/serai/rent-102160739/']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "source": [
    "sample = ['/property/kl-city/ceylonz-suites/rent-102322211/']\r\n",
    "property_url = 'https://www.iproperty.com.my' + sample[0]\r\n",
    "r = requests.get(property_url, headers=headers)  # print(r)\r\n",
    "sleep(5)\r\n",
    "soup = BeautifulSoup(r.content, 'html.parser')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "source": [
    "class Task():\r\n",
    "    def property_type(self):\r\n",
    "        if 'Property Type' in details_dict: \r\n",
    "            temp = details_dict['Property Type']\r\n",
    "            property_type.append(soup.find_all('div', class_='PropertyDetailsListstyle__AttributeItemData-jpQfWB HUTFZ')[temp].text)\r\n",
    "        else:\r\n",
    "            print('NaN')\r\n",
    "            property_type.append('NaN')\r\n",
    "\r\n",
    "    def land_title(self):\r\n",
    "        if 'Land Title' in details_dict: \r\n",
    "            temp = details_dict['Land Title']\r\n",
    "            land_title.append(soup.find_all('div', class_='PropertyDetailsListstyle__AttributeItemData-jpQfWB HUTFZ')[temp].text)\r\n",
    "        else:\r\n",
    "            print('NaN')\r\n",
    "            land_title.append('NaN')\r\n",
    "\r\n",
    "    def property_title_type(self):\r\n",
    "        if 'Property Title Type' in details_dict: \r\n",
    "            temp = details_dict['Property Title Type']\r\n",
    "            property_title_type.append(soup.find_all('div', class_='PropertyDetailsListstyle__AttributeItemData-jpQfWB HUTFZ')[temp].text)\r\n",
    "        else:\r\n",
    "            print('NaN')\r\n",
    "            property_title_type.append('NaN')\r\n",
    "\r\n",
    "    def tenure(self):\r\n",
    "        if 'Tenure' in details_dict: \r\n",
    "            temp = details_dict['Tenure']\r\n",
    "            tenure.append(soup.find_all('div', class_='PropertyDetailsListstyle__AttributeItemData-jpQfWB HUTFZ')[temp].text)\r\n",
    "        else:\r\n",
    "            print('NaN')\r\n",
    "            tenure.append('NaN')\r\n",
    "\r\n",
    "    def built_up_size_sq_ft(self):\r\n",
    "        if 'Built-up Size' in details_dict: \r\n",
    "            temp = details_dict['Built-up Size']\r\n",
    "            built_up_size_sq_ft.append(soup.find_all('div', class_='PropertyDetailsListstyle__AttributeItemData-jpQfWB HUTFZ')[temp].text)\r\n",
    "        else:\r\n",
    "            print('NaN')\r\n",
    "            built_up_size_sq_ft.append('NaN')\r\n",
    "            \r\n",
    "    def built_up_price_per_sq_ft(self):\r\n",
    "        if 'Built-up Price' in details_dict: \r\n",
    "            temp = details_dict['Built-up Price']\r\n",
    "            built_up_price_per_sq_ft.append(soup.find_all('div', class_='PropertyDetailsListstyle__AttributeItemData-jpQfWB HUTFZ')[temp].text)\r\n",
    "        else:\r\n",
    "            print('NaN')\r\n",
    "            built_up_price_per_sq_ft.append('NaN')\r\n",
    "\r\n",
    "    def furnishing(self):\r\n",
    "        if 'Furnishing' in details_dict: \r\n",
    "            temp = details_dict['Furnishing']\r\n",
    "            furnishing.append(soup.find_all('div', class_='PropertyDetailsListstyle__AttributeItemData-jpQfWB HUTFZ')[temp].text)\r\n",
    "        else:\r\n",
    "            print('NaN')\r\n",
    "            \r\n",
    "    def occupancy(self):\r\n",
    "        if 'Occupancy' in details_dict: \r\n",
    "            temp = details_dict['Occupancy']\r\n",
    "            occupancy.append(soup.find_all('div', class_='PropertyDetailsListstyle__AttributeItemData-jpQfWB HUTFZ')[temp].text)\r\n",
    "        else:\r\n",
    "            print('NaN')\r\n",
    "            occupancy.append('NaN')\r\n",
    "            \r\n",
    "    def unit_type(self):\r\n",
    "        if 'Tenure' in details_dict: \r\n",
    "            temp = details_dict['Tenure']\r\n",
    "            unit_type.append(soup.find_all('div', class_='PropertyDetailsListstyle__AttributeItemData-jpQfWB HUTFZ')[temp].text)\r\n",
    "        else:\r\n",
    "            print('NaN')\r\n",
    "            unit_type.append('NaN')\r\n",
    "            \r\n",
    "    def facing_direction(self):\r\n",
    "        if 'Facing Direction' in details_dict: \r\n",
    "            temp = details_dict['Facing Direction']\r\n",
    "            facing_direction.append(soup.find_all('div', class_='PropertyDetailsListstyle__AttributeItemData-jpQfWB HUTFZ')[temp].text)\r\n",
    "        else:\r\n",
    "            print('NaN')\r\n",
    "            facing_direction.append('NaN')\r\n",
    "            \r\n",
    "    def reference(self):\r\n",
    "        if 'Reference No.' in details_dict: \r\n",
    "            temp = details_dict['Reference No.']\r\n",
    "            reference.append(soup.find_all('div', class_='PropertyDetailsListstyle__AttributeItemData-jpQfWB HUTFZ')[temp].text)\r\n",
    "        else:\r\n",
    "            print('NaN')\r\n",
    "            reference.append('NaN')\r\n",
    "            \r\n",
    "    def available_date(self):\r\n",
    "        if 'Available Date' in details_dict: \r\n",
    "            temp = details_dict['Available Date']\r\n",
    "            available_date.append(soup.find_all('div', class_='PropertyDetailsListstyle__AttributeItemData-jpQfWB HUTFZ')[temp].text)\r\n",
    "        else:\r\n",
    "            print('NaN')\r\n",
    "            available_date.append('NaN')\r\n",
    "\r\n",
    "    def posted_date(self):\r\n",
    "        if 'Posted Date' in details_dict: \r\n",
    "            temp = details_dict['Posted Date']\r\n",
    "            posted_date.append(soup.find_all('div', class_='PropertyDetailsListstyle__AttributeItemData-jpQfWB HUTFZ')[temp].text)\r\n",
    "        else:\r\n",
    "            print('NaN')\r\n",
    "            posted_date.append('NaN')\r\n",
    "\r\n",
    "    def get_method(self, method_name):\r\n",
    "        method = getattr(self, method_name)\r\n",
    "        return method()\r\n",
    "\r\n",
    "property_type = []\r\n",
    "land_title=[]\r\n",
    "available_date=[]\r\n",
    "print(property_type)\r\n",
    "t = Task()\r\n",
    "\r\n",
    "propdetails = soup.find_all('div', class_ ='PropertyDetailsListstyle__AttributeItemTitle-gtQJBp YzpOn')\r\n",
    "# print(propdetails)\r\n",
    "# print(len(propdetails))\r\n",
    "details = [i.text for i in propdetails]\r\n",
    "details = [i.split(':') for i in details]\r\n",
    "details = [i[0] for i in details]\r\n",
    "# print(details)\r\n",
    "val = list(range(0, len(propdetails)))\r\n",
    "# print(val)\r\n",
    "details_dict = dict(zip(details, val))\r\n",
    "print(details_dict)\r\n",
    "\r\n",
    "t.property_type()\r\n",
    "t.land_title()\r\n",
    "t.available_date()\r\n",
    "\r\n",
    "print(available_date)\r\n",
    "print(property_type)\r\n",
    "print(land_title)\r\n",
    "# l = range(0, len(propdetails))\r\n",
    "# print(list(l))\r\n",
    "\r\n",
    "#IT FUCKING WORKS HERE"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[]\n",
      "{'Property Type': 0, 'Land Title': 1, 'Property Title Type': 2, 'Tenure': 3, 'Built-up Size': 4, 'Built-up Price': 5, 'Furnishing': 6, 'Occupancy': 7, 'Facing Direction': 8, 'Reference No.': 9, 'Posted Date': 10}\n",
      "NaN\n",
      "['NaN']\n",
      "['Residential']\n",
      "['Condominium']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\r\n",
    "\r\n",
    "# BeautifulSoup stuff\r\n",
    "headers = {\r\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.107 Safari/537.36'}\r\n",
    "\r\n",
    "rent_id = []\r\n",
    "title = []\r\n",
    "property_price = []\r\n",
    "property_summary = []\r\n",
    "property_address = []\r\n",
    "built_up = []\r\n",
    "land_area = []\r\n",
    "details = []\r\n",
    "#Property details\r\n",
    "property_type = []\r\n",
    "tenure = []\r\n",
    "land_title = []\r\n",
    "property_title_type = []\r\n",
    "tenure = []\r\n",
    "built_up_size_sq_ft = []\r\n",
    "built_up_price_per_sq_ft = []\r\n",
    "furnishing = []\r\n",
    "occupancy = []\r\n",
    "unit_type = []\r\n",
    "reference = []\r\n",
    "available_date =[]\r\n",
    "posted_date = []\r\n",
    "property_features = []\r\n",
    "\r\n",
    "for i in range(len(test_list)):\r\n",
    "    property_url = 'https://www.iproperty.com.my' + test_list[i]\r\n",
    "    r = requests.get(property_url, headers=headers)  # print(r)\r\n",
    "    sleep(5)\r\n",
    "    soup = BeautifulSoup(r.content, 'html.parser')\r\n",
    "\r\n",
    "    prop_name = soup.find_all(\r\n",
    "        'h1', class_='PropertySummarystyle__ProjectTitleWrapper-kAhflS PNQmp')[0].text\r\n",
    "\r\n",
    "    print('********** ' + str(i) + ' Scraping data for: ' +prop_name + ' **********')\r\n",
    "\r\n",
    "    #getting all the data from the website\r\n",
    "    rent_id.append(property_url.split('/')[6])\r\n",
    "    title.append(soup.find_all('title')[0].text)\r\n",
    "    str_price = soup.find_all('div', class_='ListingPrice__Price-cYBbuG cspQqH property-price')[\r\n",
    "        0].text.split(' ')[2].replace(',', '')\r\n",
    "    property_price.append(\r\n",
    "        int(''.join(itertools.takewhile(str.isdigit, str_price))))\r\n",
    "    property_summary.append(soup.find_all(\r\n",
    "        'h1', class_='PropertySummarystyle__ProjectTitleWrapper-kAhflS PNQmp')[0].text)\r\n",
    "    property_address.append(soup.find_all(\r\n",
    "        'span', class_='property-address rent-default')[0].text)\r\n",
    "    built_up.append(soup.find_all(\r\n",
    "        'li', class_='PropertySummarystyle__AreaInfoItem-NjZCY dUovgc')[0].text.split(': ')[1])\r\n",
    "    land_area.append(soup.find_all(\r\n",
    "        'li', class_='PropertySummarystyle__AreaInfoItem-NjZCY dUovgc')[1].text.split(': ')[1])\r\n",
    "    details.append(str(soup.find('pre')).split('>')[1].splitlines())\r\n",
    "    #Property details\r\n",
    "    property_type.append(soup.find_all(\r\n",
    "        'div', class_='PropertyDetailsListstyle__AttributeItemData-jpQfWB HUTFZ')[0].text)\r\n",
    "    land_title.append(soup.find_all(\r\n",
    "        'div', class_='PropertyDetailsListstyle__AttributeItemData-jpQfWB HUTFZ')[1].text)\r\n",
    "    property_title_type.append(soup.find_all(\r\n",
    "        'div', class_='PropertyDetailsListstyle__AttributeItemData-jpQfWB HUTFZ')[2].text)\r\n",
    "    tenure.append(soup.find_all(\r\n",
    "        'div', class_='PropertyDetailsListstyle__AttributeItemData-jpQfWB HUTFZ')[3].text)\r\n",
    "    built_up_size_sq_ft.append(soup.find_all(\r\n",
    "        'div', class_='PropertyDetailsListstyle__AttributeItemData-jpQfWB HUTFZ')[4].text.split(' ')[0])\r\n",
    "    built_up_price_per_sq_ft.append(soup.find_all(\r\n",
    "        'div', class_='PropertyDetailsListstyle__AttributeItemData-jpQfWB HUTFZ')[5].text.split(' ')[1])\r\n",
    "    furnishing.append(soup.find_all(\r\n",
    "        'div', class_='PropertyDetailsListstyle__AttributeItemData-jpQfWB HUTFZ')[6].text)\r\n",
    "    occupancy.append(soup.find_all(\r\n",
    "        'div', class_='PropertyDetailsListstyle__AttributeItemData-jpQfWB HUTFZ')[7].text)\r\n",
    "    unit_type.append(soup.find_all(\r\n",
    "        'div', class_='PropertyDetailsListstyle__AttributeItemData-jpQfWB HUTFZ')[8].text)\r\n",
    "    reference.append(soup.find_all(\r\n",
    "        'div', class_='PropertyDetailsListstyle__AttributeItemData-jpQfWB HUTFZ')[9].text)\r\n",
    "    posted_date.append(pd.to_datetime(soup.find_all(\r\n",
    "        'div', class_='PropertyDetailsListstyle__AttributeItemData-jpQfWB HUTFZ')[10].text))\r\n",
    "    property_features.append([i.text for i in soup.find_all(\r\n",
    "        'div', class_='attribute-title-container')])\r\n",
    "    print(rent_id)\r\n",
    "    print(title)\r\n",
    "    print(property_price)\r\n",
    "    print(property_summary)\r\n",
    "    print(property_address)\r\n",
    "    print(built_up)\r\n",
    "    print(land_area)\r\n",
    "    print(details)\r\n",
    "    print(property_type)\r\n",
    "    print(land_title)\r\n",
    "    print(property_title_type)\r\n",
    "    print(tenure)\r\n",
    "    print(built_up_size_sq_ft)\r\n",
    "    print(built_up_price_per_sq_ft)\r\n",
    "    print(furnishing)\r\n",
    "    print(occupancy)\r\n",
    "    print(unit_type)\r\n",
    "    print(reference)\r\n",
    "    print(posted_date)\r\n",
    "    print(property_features)\r\n",
    "\r\n",
    "\r\n",
    "print('\\n********** SCRAPE COMPLETED **********')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# print(soup.prettify())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "source": [
    "# a = str(soup.find_all('pre'))\r\n",
    "# a=soup.find_all('h2', class_ =\"contact-name agent\")\r\n",
    "# a\r\n",
    "# print(type(a))\r\n",
    "# print(len(a))\r\n",
    "# # print(type(a))\r\n",
    "\r\n",
    "\r\n",
    "# b = float(soup.find_all('div', class_ ='PropertyDetailsListstyle__AttributeItemData-jpQfWB HUTFZ')[5].text.split(' ')[1])\r\n",
    "\r\n",
    "# print(b)\r\n",
    "# print(type(b))\r\n",
    "# # .text.split(': ')[1]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "metadata": {},
     "execution_count": 116
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# rent_id = sample.split('/')[4]\r\n",
    "# title = soup.find_all('title')[0].text\r\n",
    "# str_price = soup.find_all('div', class_ ='ListingPrice__Price-cYBbuG cspQqH property-price')[0].text.split(' ')[2].replace(',','')\r\n",
    "# property_price = int(''.join(itertools.takewhile(str.isdigit,str_price)))\r\n",
    "# property_summary = soup.find_all('h1', class_ ='PropertySummarystyle__ProjectTitleWrapper-kAhflS PNQmp')[0].text\r\n",
    "# property_address = soup.find_all('span', class_ ='property-address rent-default')[0].text\r\n",
    "# built_up = soup.find_all('li', class_ ='PropertySummarystyle__AreaInfoItem-NjZCY dUovgc')[0].text.split(': ')[1]\r\n",
    "# land_area = soup.find_all('li', class_ ='PropertySummarystyle__AreaInfoItem-NjZCY dUovgc')[1].text.split(': ')[1]\r\n",
    "# details = str(soup.find('pre')).split('>')[1].splitlines()\r\n",
    "# property_type = soup.find_all('div', class_ ='PropertyDetailsListstyle__AttributeItemData-jpQfWB HUTFZ')[0].text\r\n",
    "# land_title = soup.find_all('div', class_ ='PropertyDetailsListstyle__AttributeItemData-jpQfWB HUTFZ')[1].text\r\n",
    "# property_title_type = soup.find_all('div', class_ ='PropertyDetailsListstyle__AttributeItemData-jpQfWB HUTFZ')[2].text\r\n",
    "# tenure = soup.find_all('div', class_ ='PropertyDetailsListstyle__AttributeItemData-jpQfWB HUTFZ')[3].text\r\n",
    "# built_up_size_sq_ft = int(''.join(itertools.takewhile(str.isdigit,soup.find_all('div', class_ ='PropertyDetailsListstyle__AttributeItemData-jpQfWB HUTFZ')[4].text.split(' ')[0].replace(',', ''))))\r\n",
    "# built_up_price_per_sq_ft = float(soup.find_all('div', class_ ='PropertyDetailsListstyle__AttributeItemData-jpQfWB HUTFZ')[5].text.split(' ')[1])\r\n",
    "# furnishing = soup.find_all('div', class_ ='PropertyDetailsListstyle__AttributeItemData-jpQfWB HUTFZ')[6].text\r\n",
    "# occupancy = soup.find_all('div', class_ ='PropertyDetailsListstyle__AttributeItemData-jpQfWB HUTFZ')[7].text\r\n",
    "# unit_type = soup.find_all('div', class_ ='PropertyDetailsListstyle__AttributeItemData-jpQfWB HUTFZ')[8].text\r\n",
    "# reference = int(soup.find_all('div', class_ ='PropertyDetailsListstyle__AttributeItemData-jpQfWB HUTFZ')[9].text)\r\n",
    "# posted_date = pd.to_datetime(soup.find_all('div', class_ ='PropertyDetailsListstyle__AttributeItemData-jpQfWB HUTFZ')[10].text)\r\n",
    "# property_features = [i.text for i in soup.find_all('div', class_ ='attribute-title-container')]\r\n",
    "\r\n",
    "\r\n",
    "# # print(rent_id)\r\n",
    "# # print(title)\r\n",
    "# # print(property_price)\r\n",
    "# # print(property_summary)\r\n",
    "# # print(property_address)\r\n",
    "# # print(built_up)\r\n",
    "# # print(land_area)\r\n",
    "# # print(details)\r\n",
    "# # print(property_type)\r\n",
    "# # print(land_title)\r\n",
    "# # print(property_title_type)\r\n",
    "# # print(tenure)\r\n",
    "# # print(built_up_size_sq_ft)\r\n",
    "# # print(built_up_price_per_sq_ft)\r\n",
    "# # print(furnishing)\r\n",
    "# # print(occupancy)\r\n",
    "# # print(unit_type)\r\n",
    "# # print(reference)\r\n",
    "# # print(posted_date)\r\n",
    "# # print(property_features)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "9359f96dcc8e6dbb808894a2b8636b1a27bb05921e7737a9fa6a11f3018a2953"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}