{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Get all links for a given Train Station ID"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train Station ID's"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "lrt_kelana_jaya_line_1 = ['gombak-543', 'ampang-park-89', 'pasar-seni-414', 'bangsar-625', 'asia-jaya-187', 'ara-damansara-415', 'usj-7-608', 'putra-heights-678', 'taman-melati-624', 'jelatek-51', 'masjid-jamek-600', 'abdullah-hukum-325', 'taman-paramount-466', 'glenmarie-250', 'taipan-719', 'subang-alam-584', 'wangsa-maju-276', 'dato-keramat-607', 'kampung-baru-121', 'kerinchi-431', 'taman-bahagia-529', 'subang-jaya-1', 'wawasan-432', 'sri-rampai-513', 'damai-683', 'dang-wangi-291', 'universiti-168', 'kelana-jaya-260', 'ss-15-316', 'usj-21-531', 'setiawangsa-20', 'klcc-666', 'kl-sentral-438', 'taman-jaya-560', 'lembah-subang-170', 'ss-18-189', 'alam-megah-23']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Get all links from a Train Station ID"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import requests\r\n",
    "from bs4 import BeautifulSoup\r\n",
    "from time import sleep\r\n",
    "from itertools import chain\r\n",
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "import re"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# url = 'https://www.iproperty.com.my/rent/all-residential/transport/kl-sentral-438'\r\n",
    "# headers = {'User-Agent' : 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.107 Safari/537.36'}\r\n",
    "# response= requests.get(url, headers=headers)\r\n",
    "# print(response)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# BeautifulSoup stuff\r\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.107 Safari/537.36'}\r\n",
    "\r\n",
    "page_num = 0\r\n",
    "\r\n",
    "links = []\r\n",
    "for page in range(0,1):\r\n",
    "    page_num += 1\r\n",
    "    iproperty_url = 'https://www.iproperty.com.my/rent/all-residential/transport/kl-sentral-438/?page=' + \\\r\n",
    "        str(page_num)\r\n",
    "    r = requests.get(iproperty_url, headers=headers)\r\n",
    "    print(r)\r\n",
    "    sleep(5)\r\n",
    "    print('Now scraping page ' +str(page_num))\r\n",
    "    soup = BeautifulSoup(r.content, 'html.parser')\r\n",
    "    for link in soup.findAll('a'):\r\n",
    "        # print(link.get('href'))\r\n",
    "        links.append(link.get('href'))\r\n",
    "\r\n",
    "links = [i for i in links if i] #removes None\r\n",
    "print(len(links))\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "print('**********ALL LINKS FOR TRAIN STATION ID: ' + 'COMPLETE**********')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "to_remove = ['http','tel','photo','video','floorplan']\r\n",
    "\r\n",
    "filtered_list = [ i for i in links if \"http\" not in i and \"tel\" not in i and \"photo\" not in i and \"video\" not in i and \"floorplan\" not in i and len(i) > 10]\r\n",
    "\r\n",
    "# for loop implementation\r\n",
    "# for i in links:\r\n",
    "#     if \"http\" not in i and \"tel\" not in i and \"photo\" not in i and \"video\" not in i and \"floorplan\" not in i and len(i) > 10:\r\n",
    "#         nlist.append(i)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df = pd.DataFrame(filtered_list, columns=[\"links\"])\r\n",
    "\r\n",
    "df.drop_duplicates(inplace=True)\r\n",
    "\r\n",
    "filename = iproperty_url.split('/')\r\n",
    "filename = filename[3] + '-' + filename[6] + '-' + 'property-links' + '.csv'\r\n",
    "\r\n",
    "df.to_csv(filename, index=False) #to print to a csv"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Scrape data from just 1 property link"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "import requests\r\n",
    "from bs4 import BeautifulSoup\r\n",
    "from time import sleep\r\n",
    "import itertools\r\n",
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "import re"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# sample = ['/property/kl-city/ceylonz-suites/rent-102322211/']\r\n",
    "# sample2 = '/property/bangsar/serai/rent-101410606/'\r\n",
    "\r\n",
    "# url = 'https://www.iproperty.com.my' + sample2\r\n",
    "# url\r\n",
    "\r\n",
    "# d = pd.read_csv('hardcopy-rent-kl-sentral-438-property-links.csv').values.tolist()\r\n",
    "# links = list(itertools.chain(*d))\r\n",
    "\r\n",
    "# test_list = links[0:2]\r\n",
    "\r\n",
    "# print(test_list)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# headers = {'User-Agent' : 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.107 Safari/537.36'}\r\n",
    "# response= requests.get(url, headers=headers)\r\n",
    "# print(response)\r\n",
    "\r\n",
    "# soup = BeautifulSoup(response.content, 'html.parser')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "d = pd.read_csv(\r\n",
    "    'hardcopy-rent-kl-sentral-438-property-links.csv').values.tolist()\r\n",
    "links = list(itertools.chain(*d))\r\n",
    "test_list = links[3:5]\r\n",
    "\r\n",
    "print('\\n')\r\n",
    "print(test_list)\r\n",
    "print('\\n')\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "\n",
      "['/property/kl-city/ceylonz-suites/rent-102322211/', '/property/bangsar/serai/rent-102160739/']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "sample = ['/property/bangsar/serai/rent-101410606/']\r\n",
    "property_url = 'https://www.iproperty.com.my' + sample[0]\r\n",
    "r = requests.get(property_url, headers=headers)  # print(r)\r\n",
    "sleep(5)\r\n",
    "soup = BeautifulSoup(r.content, 'html.parser')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "propdeets = soup.find_all('div', class_ ='PropertyDetailsListstyle__AttributeItemTitle-gtQJBp YzpOn')\r\n",
    "\r\n",
    "deets = [i.text for i in propdeets]\r\n",
    "print(deets)\r\n",
    "len(deets)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['Property Type:', 'Land Title:', 'Property Title Type:', 'Tenure:', 'Built-up Size:', 'Built-up Price:', 'Furnishing:', 'Occupancy:', 'Facing Direction:', 'Reference No.:', 'Posted Date:']\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\r\n",
    "\r\n",
    "# BeautifulSoup stuff\r\n",
    "headers = {\r\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.107 Safari/537.36'}\r\n",
    "\r\n",
    "rent_id = []\r\n",
    "title = []\r\n",
    "property_price = []\r\n",
    "property_summary = []\r\n",
    "property_address = []\r\n",
    "built_up = []\r\n",
    "land_area = []\r\n",
    "details = []\r\n",
    "#Property details\r\n",
    "property_type = []\r\n",
    "tenure = []\r\n",
    "land_title = []\r\n",
    "property_title_type = []\r\n",
    "tenure = []\r\n",
    "built_up_size_sq_ft = []\r\n",
    "built_up_price_per_sq_ft = []\r\n",
    "furnishing = []\r\n",
    "occupancy = []\r\n",
    "unit_type = []\r\n",
    "reference = []\r\n",
    "available_date =[]\r\n",
    "posted_date = []\r\n",
    "property_features = []\r\n",
    "\r\n",
    "for i in range(len(test_list)):\r\n",
    "    property_url = 'https://www.iproperty.com.my' + test_list[i]\r\n",
    "    r = requests.get(property_url, headers=headers)  # print(r)\r\n",
    "    sleep(5)\r\n",
    "    soup = BeautifulSoup(r.content, 'html.parser')\r\n",
    "\r\n",
    "    prop_name = soup.find_all(\r\n",
    "        'h1', class_='PropertySummarystyle__ProjectTitleWrapper-kAhflS PNQmp')[0].text\r\n",
    "\r\n",
    "    print('********** ' + str(i) + ' Scraping data for: ' +prop_name + ' **********')\r\n",
    "\r\n",
    "    #getting all the data from the website\r\n",
    "    rent_id.append(property_url.split('/')[6])\r\n",
    "    title.append(soup.find_all('title')[0].text)\r\n",
    "    str_price = soup.find_all('div', class_='ListingPrice__Price-cYBbuG cspQqH property-price')[\r\n",
    "        0].text.split(' ')[2].replace(',', '')\r\n",
    "    property_price.append(\r\n",
    "        int(''.join(itertools.takewhile(str.isdigit, str_price))))\r\n",
    "    property_summary.append(soup.find_all(\r\n",
    "        'h1', class_='PropertySummarystyle__ProjectTitleWrapper-kAhflS PNQmp')[0].text)\r\n",
    "    property_address.append(soup.find_all(\r\n",
    "        'span', class_='property-address rent-default')[0].text)\r\n",
    "    built_up.append(soup.find_all(\r\n",
    "        'li', class_='PropertySummarystyle__AreaInfoItem-NjZCY dUovgc')[0].text.split(': ')[1])\r\n",
    "    land_area.append(soup.find_all(\r\n",
    "        'li', class_='PropertySummarystyle__AreaInfoItem-NjZCY dUovgc')[1].text.split(': ')[1])\r\n",
    "    details.append(str(soup.find('pre')).split('>')[1].splitlines())\r\n",
    "    #Property details\r\n",
    "    property_type.append(soup.find_all(\r\n",
    "        'div', class_='PropertyDetailsListstyle__AttributeItemData-jpQfWB HUTFZ')[0].text)\r\n",
    "    land_title.append(soup.find_all(\r\n",
    "        'div', class_='PropertyDetailsListstyle__AttributeItemData-jpQfWB HUTFZ')[1].text)\r\n",
    "    property_title_type.append(soup.find_all(\r\n",
    "        'div', class_='PropertyDetailsListstyle__AttributeItemData-jpQfWB HUTFZ')[2].text)\r\n",
    "    tenure.append(soup.find_all(\r\n",
    "        'div', class_='PropertyDetailsListstyle__AttributeItemData-jpQfWB HUTFZ')[3].text)\r\n",
    "    built_up_size_sq_ft.append(soup.find_all(\r\n",
    "        'div', class_='PropertyDetailsListstyle__AttributeItemData-jpQfWB HUTFZ')[4].text.split(' ')[0])\r\n",
    "    built_up_price_per_sq_ft.append(soup.find_all(\r\n",
    "        'div', class_='PropertyDetailsListstyle__AttributeItemData-jpQfWB HUTFZ')[5].text.split(' ')[1])\r\n",
    "    furnishing.append(soup.find_all(\r\n",
    "        'div', class_='PropertyDetailsListstyle__AttributeItemData-jpQfWB HUTFZ')[6].text)\r\n",
    "    occupancy.append(soup.find_all(\r\n",
    "        'div', class_='PropertyDetailsListstyle__AttributeItemData-jpQfWB HUTFZ')[7].text)\r\n",
    "    unit_type.append(soup.find_all(\r\n",
    "        'div', class_='PropertyDetailsListstyle__AttributeItemData-jpQfWB HUTFZ')[8].text)\r\n",
    "    reference.append(soup.find_all(\r\n",
    "        'div', class_='PropertyDetailsListstyle__AttributeItemData-jpQfWB HUTFZ')[9].text)\r\n",
    "    posted_date.append(pd.to_datetime(soup.find_all(\r\n",
    "        'div', class_='PropertyDetailsListstyle__AttributeItemData-jpQfWB HUTFZ')[10].text))\r\n",
    "    property_features.append([i.text for i in soup.find_all(\r\n",
    "        'div', class_='attribute-title-container')])\r\n",
    "    print(rent_id)\r\n",
    "    print(title)\r\n",
    "    print(property_price)\r\n",
    "    print(property_summary)\r\n",
    "    print(property_address)\r\n",
    "    print(built_up)\r\n",
    "    print(land_area)\r\n",
    "    print(details)\r\n",
    "    print(property_type)\r\n",
    "    print(land_title)\r\n",
    "    print(property_title_type)\r\n",
    "    print(tenure)\r\n",
    "    print(built_up_size_sq_ft)\r\n",
    "    print(built_up_price_per_sq_ft)\r\n",
    "    print(furnishing)\r\n",
    "    print(occupancy)\r\n",
    "    print(unit_type)\r\n",
    "    print(reference)\r\n",
    "    print(posted_date)\r\n",
    "    print(property_features)\r\n",
    "\r\n",
    "\r\n",
    "print('\\n********** SCRAPE COMPLETED **********')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# print(soup.prettify())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# a = soup.find_all('div', class_ ='PropertyDetailsListstyle__AttributeItemData-jpQfWB HUTFZ')[5].text.split(' ')[1]\r\n",
    "\r\n",
    "# print(a)\r\n",
    "# print(type(a))\r\n",
    "\r\n",
    "\r\n",
    "# b = float(soup.find_all('div', class_ ='PropertyDetailsListstyle__AttributeItemData-jpQfWB HUTFZ')[5].text.split(' ')[1])\r\n",
    "\r\n",
    "# print(b)\r\n",
    "# print(type(b))\r\n",
    "# # .text.split(': ')[1]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# rent_id = sample.split('/')[4]\r\n",
    "# title = soup.find_all('title')[0].text\r\n",
    "# str_price = soup.find_all('div', class_ ='ListingPrice__Price-cYBbuG cspQqH property-price')[0].text.split(' ')[2].replace(',','')\r\n",
    "# property_price = int(''.join(itertools.takewhile(str.isdigit,str_price)))\r\n",
    "# property_summary = soup.find_all('h1', class_ ='PropertySummarystyle__ProjectTitleWrapper-kAhflS PNQmp')[0].text\r\n",
    "# property_address = soup.find_all('span', class_ ='property-address rent-default')[0].text\r\n",
    "# built_up = soup.find_all('li', class_ ='PropertySummarystyle__AreaInfoItem-NjZCY dUovgc')[0].text.split(': ')[1]\r\n",
    "# land_area = soup.find_all('li', class_ ='PropertySummarystyle__AreaInfoItem-NjZCY dUovgc')[1].text.split(': ')[1]\r\n",
    "# details = str(soup.find('pre')).split('>')[1].splitlines()\r\n",
    "# property_type = soup.find_all('div', class_ ='PropertyDetailsListstyle__AttributeItemData-jpQfWB HUTFZ')[0].text\r\n",
    "# land_title = soup.find_all('div', class_ ='PropertyDetailsListstyle__AttributeItemData-jpQfWB HUTFZ')[1].text\r\n",
    "# property_title_type = soup.find_all('div', class_ ='PropertyDetailsListstyle__AttributeItemData-jpQfWB HUTFZ')[2].text\r\n",
    "# tenure = soup.find_all('div', class_ ='PropertyDetailsListstyle__AttributeItemData-jpQfWB HUTFZ')[3].text\r\n",
    "# built_up_size_sq_ft = int(''.join(itertools.takewhile(str.isdigit,soup.find_all('div', class_ ='PropertyDetailsListstyle__AttributeItemData-jpQfWB HUTFZ')[4].text.split(' ')[0].replace(',', ''))))\r\n",
    "# built_up_price_per_sq_ft = float(soup.find_all('div', class_ ='PropertyDetailsListstyle__AttributeItemData-jpQfWB HUTFZ')[5].text.split(' ')[1])\r\n",
    "# furnishing = soup.find_all('div', class_ ='PropertyDetailsListstyle__AttributeItemData-jpQfWB HUTFZ')[6].text\r\n",
    "# occupancy = soup.find_all('div', class_ ='PropertyDetailsListstyle__AttributeItemData-jpQfWB HUTFZ')[7].text\r\n",
    "# unit_type = soup.find_all('div', class_ ='PropertyDetailsListstyle__AttributeItemData-jpQfWB HUTFZ')[8].text\r\n",
    "# reference = int(soup.find_all('div', class_ ='PropertyDetailsListstyle__AttributeItemData-jpQfWB HUTFZ')[9].text)\r\n",
    "# posted_date = pd.to_datetime(soup.find_all('div', class_ ='PropertyDetailsListstyle__AttributeItemData-jpQfWB HUTFZ')[10].text)\r\n",
    "# property_features = [i.text for i in soup.find_all('div', class_ ='attribute-title-container')]\r\n",
    "\r\n",
    "\r\n",
    "# # print(rent_id)\r\n",
    "# # print(title)\r\n",
    "# # print(property_price)\r\n",
    "# # print(property_summary)\r\n",
    "# # print(property_address)\r\n",
    "# # print(built_up)\r\n",
    "# # print(land_area)\r\n",
    "# # print(details)\r\n",
    "# # print(property_type)\r\n",
    "# # print(land_title)\r\n",
    "# # print(property_title_type)\r\n",
    "# # print(tenure)\r\n",
    "# # print(built_up_size_sq_ft)\r\n",
    "# # print(built_up_price_per_sq_ft)\r\n",
    "# # print(furnishing)\r\n",
    "# # print(occupancy)\r\n",
    "# # print(unit_type)\r\n",
    "# # print(reference)\r\n",
    "# # print(posted_date)\r\n",
    "# # print(property_features)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "9359f96dcc8e6dbb808894a2b8636b1a27bb05921e7737a9fa6a11f3018a2953"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}